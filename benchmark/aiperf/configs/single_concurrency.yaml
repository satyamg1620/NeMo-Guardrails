# Single-run AIPerf benchmark configuration

# Name for this batch of benchmarks (will be part of output directory name)
batch_name: single_concurrency

# Base directory where all benchmark results will be stored.
# Actual name is <output_base_dir>/<batch_name>/<sweep value>
output_base_dir: aiperf_results

# Base configuration applied to all benchmark runs
# These parameters can be overridden by sweep parameters
base_config:
  # Model details
  model: meta/llama-3.3-70b-instruct
  tokenizer: meta-llama/Llama-3.3-70B-Instruct
  url: "https://integrate.api.nvidia.com"
  endpoint: "/v1/chat/completions"
  endpoint_type: chat
  api_key_env_var: NVIDIA_API_KEY
  streaming: True

  # Load generation settings.
  warmup_request_count: 20
  benchmark_duration: 60
  concurrency: 1
  request_rate_mode: "constant"

  # Synthetic data generation
  random_seed: 12345
  prompt_input_tokens_mean: 100
  prompt_input_tokens_stddev: 10
  prompt_output_tokens_mean: 50
  prompt_output_tokens_stddev: 5
