# Concurrency sweep. One-minute tests at log-spaced concurrencies

# Name for this batch of benchmarks (will be part of output directory name)
batch_name: sweep_concurrency

# Base directory where all benchmark results will be stored.
# Actual name is <output_base_dir>/<batch_name>/<sweep value> for sweeps
output_base_dir: aiperf_results

# Base configuration applied to all benchmark runs
# These parameters can be overridden by sweep parameters
base_config:
  # Model details
  model: meta/llama-3.3-70b-instruct
  tokenizer: meta-llama/Llama-3.3-70B-Instruct
  url: "https://integrate.api.nvidia.com"
  endpoint: "/v1/chat/completions"
  endpoint_type: chat
  api_key_env_var: NVIDIA_API_KEY

  # Load generation settings.
  warmup_request_count: 10
  benchmark_duration: 60
  concurrency: 0  # Overridden by the concurrency sweep below
  request_rate_mode: "constant"

  # Synthetic data generation
  random_seed: 12345
  prompt_input_tokens_mean: 100
  prompt_input_tokens_stddev: 10
  prompt_output_tokens_mean: 50
  prompt_output_tokens_stddev: 5

# Parameter sweeps. Each parameter can have multiple values
# The script will run all combinations (Cartesian product)
sweeps:
  # Sweep over the following concurrency values
  concurrency: [1, 2, 4]
